{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPAssignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhZ-SKnmSUR-",
        "colab_type": "code",
        "outputId": "76cb93ac-1f9d-45f6-dd57-99595785a589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Import the pandas library to read our dataset \n",
        "import pandas as pd\n",
        "\n",
        "# Get the train/test split package from sklearn for preparing our dataset to # train and test the model with \n",
        "from sklearn.model_selection import train_test_split\n",
        "# Import the numpy library to work with and manipulate the data \n",
        "# Get the train/test split package from sklearn for preparing our dataset to\n",
        "# train and test the model with\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(color_codes=True)\n",
        "\n",
        "import nltk \n",
        "import random \n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt') \n",
        "nltk.download('stopwords') \n",
        "#nltk.download('movie_reviews') \n",
        "nltk.download('wordnet') "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzgCW0E6SZQe",
        "colab_type": "code",
        "outputId": "1480692b-66f9-4366-ade1-671b3a738663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Imported the necessary libraries\n",
        "import csv\n",
        "import urllib.request as urllib2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk import FreqDist\n",
        "import pandas as pd\n",
        "# Importing data using url\n",
        "url = 'https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv'\n",
        "response = urllib2.urlopen(url)\n",
        "\n",
        "# reading data using pandas and converting into dataframe\n",
        "df = pd.read_csv(response,delimiter='\\t',encoding='utf-8')\n",
        "df.head()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDU5qDu_Sbj2",
        "colab_type": "code",
        "outputId": "f431f1af-d858-4735-b088-a2c91bfdb371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>119228</td>\n",
              "      <td>6373</td>\n",
              "      <td>A good film with a solid pedigree both in fron...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>117134</td>\n",
              "      <td>6249</td>\n",
              "      <td>these characters ' foibles</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>152498</td>\n",
              "      <td>8321</td>\n",
              "      <td>the characters are too simplistic to maintain ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19482</td>\n",
              "      <td>854</td>\n",
              "      <td>A somewhat disappointing and meandering saga</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32161</td>\n",
              "      <td>1506</td>\n",
              "      <td>drung</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0    119228  ...          3\n",
              "1    117134  ...          2\n",
              "2    152498  ...          1\n",
              "3     19482  ...          1\n",
              "4     32161  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I09uWbN4SfNm",
        "colab_type": "code",
        "outputId": "74c091e9-4f37-4ef4-da5b-28810475ec62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(df ['Phrase'], df ['Sentiment'], test_size=0.3, random_state=2003)\n",
        "documents=[]\n",
        "X_train = np.array(X_train.values.tolist())\n",
        "Y_train = np.array(Y_train.values.tolist())\n",
        "\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "  documents.append([list(word_tokenize(X_train[i])), Y_train[i]]) \n",
        "\n",
        "X_test = np.array(X_test.values.tolist())\n",
        "Y_test = np.array(Y_test.values.tolist())\n",
        "for i in range(len(X_test)):\n",
        "  documents.append([list(word_tokenize(X_test[i])), Y_test[i]]) \n",
        "\n",
        "documents[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['a', 'solid', 'success'], 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6ccNGN3WvQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer \n",
        "porter = PorterStemmer() \n",
        "lancaster=LancasterStemmer() \n",
        "wordnet_lemmatizer = WordNetLemmatizer() \n",
        "stopwords_en = stopwords.words(\"english\") \n",
        "punctuations=\"?:!.,;'\\\"-()\"\n",
        "#parameters to adjust to see the impact on outcome \n",
        "remove_stopwords = True\n",
        "useStemming = False\n",
        "useLemma = False\n",
        "removePuncs = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wibkp1lHWxuf",
        "colab_type": "code",
        "outputId": "60be3c9f-cac1-449a-a545-7d1b6d9c99a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for l in range(len(documents)):                   #For each review document \n",
        "  label = documents[l][1]                         #Save review label \n",
        "  tmpReview = []                                  #Placeholder list for new review \n",
        "  for w in documents[l][0]:                       #For each word this is review \n",
        "    newWord = w                                   #Set newWork to be the updated word \n",
        "    if remove_stopwords and (w in stopwords_en):  #if the word is a stopword & we want to remove stopwords \n",
        "      continue                                    #skip the word and don’t had it to the normalized review \n",
        "    if removePuncs and (w in punctuations):       #if the word is a punc. & we want to remove punctuations \n",
        "      continue                                    #skip the word and don’t had it to the normalized review \n",
        "    if useStemming:\n",
        "      #if useStemming is set to True \n",
        "      #Keep one stemmer commented out \n",
        "      #newWord = porter.stem(newWord) #User porter stemmer \n",
        "      newWord = lancaster.stem(newWord) #Use Lancaster stemmer \n",
        "    if useLemma: \n",
        "      newWord = wordnet_lemmatizer.lemmatize(newWord) \n",
        "    tmpReview.append(newWord)                     #Add normalized word to the tmp review \n",
        "  documents[l] = (tmpReview, label)             #Update the reviews list with clean review \n",
        "  documents[l] = (' '.join(tmpReview), label) \n",
        "\n",
        "print(documents[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('solid success', 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InPVUfgzWztX",
        "colab_type": "code",
        "outputId": "31d2a123-8df8-452a-d215-88b1a919dcd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.DataFrame(documents, columns=['text', 'sentiment']) \n",
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>solid success</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>diabolical</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>push audience 's meat grinder one</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Barrie</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cage makes unusual pleasantly haunting debut b...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment\n",
              "0                                      solid success          4\n",
              "1                                         diabolical          2\n",
              "2                  push audience 's meat grinder one          2\n",
              "3                                             Barrie          2\n",
              "4  Cage makes unusual pleasantly haunting debut b...          3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSoEouQN83iF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(df['text'],  df['sentiment'], test_size=0.3, random_state=2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gaF2YPvUH7W",
        "colab_type": "code",
        "outputId": "6ec13631-6193-42a9-e802-8bde94467f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features = 2500)#,ngram_range=(2, 2)) \n",
        "X = vectorizer.fit_transform(df[\"text\"]) \n",
        "Y = df['sentiment'] \n",
        " \n",
        "X_train = vectorizer.transform(X_train).toarray()\n",
        "Y_train = Y_train \n",
        "X_test = vectorizer.transform(X_test).toarray()\n",
        "Y_test = Y_test\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezvrFic8Uqyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx8g8sDt2IbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfzeNFfVU4rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "num_classes = 5\n",
        "epochs = 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5AlEWbzSCMP",
        "colab_type": "code",
        "outputId": "cd8a7a67-9f32-44a9-a89a-e2884660dff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape\n",
        "# Y_train = to_categorical(Y_train,5)\n",
        "# y_test = to_categorical(y_test,5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109242, 2500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBxQFt--fHT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
        "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL4Ml-k0LhLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, Embedding, Flatten\n",
        "from keras.layers import SpatialDropout1D\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.models import Sequential\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5ToySXMU87V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=5,\n",
        "                 activation='relu',\n",
        "                 input_shape=(2500,1)))\n",
        "model.add(Conv1D(128, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=1))\n",
        "# model.add(Dropout(rate = 0.50))\n",
        "model.add(Flatten())\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA3I6AgtgMaN",
        "colab_type": "code",
        "outputId": "950adf8e-d36f-4d26-ad74-e40a13ae3bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy', f1_m, precision_m, recall_m])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rXqFVIQiS-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sDSZ7J2ViP8",
        "colab_type": "code",
        "outputId": "1582c094-02af-4cca-fd26-6d0db4bd776b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "import time\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=64,\n",
        "          epochs=12)\n",
        "# _, accuracy = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=0)\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "print('Test F1:', score[2])\n",
        "print('Test precision:', score[3])\n",
        "print('Test recall:', score[4])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/12\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "109242/109242 [==============================] - 62s 565us/step - loss: 1.1176 - acc: 0.5639 - f1_m: 0.4891 - precision_m: 0.6112 - recall_m: 0.4148\n",
            "Epoch 2/12\n",
            "109242/109242 [==============================] - 48s 439us/step - loss: 1.0153 - acc: 0.6051 - f1_m: 0.5672 - precision_m: 0.6655 - recall_m: 0.4957\n",
            "Epoch 3/12\n",
            "109242/109242 [==============================] - 48s 443us/step - loss: 0.9916 - acc: 0.6149 - f1_m: 0.5816 - precision_m: 0.6722 - recall_m: 0.5139\n",
            "Epoch 4/12\n",
            "109242/109242 [==============================] - 48s 441us/step - loss: 0.9788 - acc: 0.6212 - f1_m: 0.5892 - precision_m: 0.6756 - recall_m: 0.5238\n",
            "Epoch 5/12\n",
            "109242/109242 [==============================] - 48s 442us/step - loss: 0.9685 - acc: 0.6253 - f1_m: 0.5959 - precision_m: 0.6782 - recall_m: 0.5327\n",
            "Epoch 6/12\n",
            "109242/109242 [==============================] - 48s 441us/step - loss: 0.9592 - acc: 0.6288 - f1_m: 0.6001 - precision_m: 0.6796 - recall_m: 0.5385\n",
            "Epoch 7/12\n",
            "109242/109242 [==============================] - 48s 439us/step - loss: 0.9513 - acc: 0.6305 - f1_m: 0.6045 - precision_m: 0.6815 - recall_m: 0.5443\n",
            "Epoch 8/12\n",
            "109242/109242 [==============================] - 48s 438us/step - loss: 0.9446 - acc: 0.6347 - f1_m: 0.6085 - precision_m: 0.6838 - recall_m: 0.5493\n",
            "Epoch 9/12\n",
            "109242/109242 [==============================] - 48s 439us/step - loss: 0.9397 - acc: 0.6371 - f1_m: 0.6125 - precision_m: 0.6862 - recall_m: 0.5542\n",
            "Epoch 10/12\n",
            "109242/109242 [==============================] - 49s 445us/step - loss: 0.9349 - acc: 0.6389 - f1_m: 0.6149 - precision_m: 0.6869 - recall_m: 0.5577\n",
            "Epoch 11/12\n",
            "109242/109242 [==============================] - 49s 446us/step - loss: 0.9303 - acc: 0.6408 - f1_m: 0.6165 - precision_m: 0.6871 - recall_m: 0.5602\n",
            "Epoch 12/12\n",
            "109242/109242 [==============================] - 49s 446us/step - loss: 0.9255 - acc: 0.6427 - f1_m: 0.6200 - precision_m: 0.6890 - recall_m: 0.5647\n",
            "Test loss: 1.0049425748021035\n",
            "Test accuracy: 0.6147635524798154\n",
            "Test F1: 0.5848887968569545\n",
            "Test precision: 0.6690445471626766\n",
            "Test recall: 0.5215728993122304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIWGmcD2hYxW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4357cb5c-90d0-4b27-c88c-9c899a402359"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2hc-0qXhCtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/1111405-1DConvReg.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}